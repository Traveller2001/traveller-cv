---
title: Foundation Model Intern
summary: Investigated Transformer redundancy and proposed layer-based pruning methods.
date: '2024-01-01'
company: Baichuan Intelligence
company_url: 'https://www.baichuan-ai.com/'
location: Beijing, China
date_start: '2024-01-01'
date_end: '2024-10-31'
---

* Investigated Transformer redundancy and proposed a layer-based pruning method (**ShortGPT**, *ACL Findings*, 2025).
* Researched the lower bounds of RoPE Base (**Base of RoPE Bounds Context Length**, *NeurIPS*, 2024).
* Proposed a variant of the "Needle in a Haystack" evaluation method (Patent Granted).
