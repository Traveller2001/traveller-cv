---
title: Inference Acceleration for the 70B LLaMA-2 Large Language Model
summary: 'As a coaching assistant for the ASC24 Student Supercomputer Challenge, I helped the team optimize the inference performance of the LLaMA-2-70B model using efficient frameworks like vLLM and designed data parallelism strategies to significantly reduce latency.'
tags:
- Large Language Models
- Inference Acceleration
- vLLM
- ASC24
date: "2024-04-30"

# Optional external link for project
external_link: ''

image:
  caption: ''
  focal_point: Smart
---